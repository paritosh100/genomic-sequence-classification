{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvIuXTSnx0NP",
    "outputId": "125bcf21-e9e6-47cd-c79e-1c2786807757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hmmlearn in c:\\users\\legion\\anaconda3\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\legion\\appdata\\roaming\\python\\python312\\site-packages (from hmmlearn) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in c:\\users\\legion\\appdata\\roaming\\python\\python312\\site-packages (from hmmlearn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\legion\\appdata\\roaming\\python\\python312\\site-packages (from hmmlearn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\legion\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\legion\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ucYbQun6xyND"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1lqV6qfNx3nX"
   },
   "outputs": [],
   "source": [
    "def encode_sequence(seq):\n",
    "    return [nucleotide_map[nuc] for nuc in seq if nuc in nucleotide_map]\n",
    "\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath, sep=\"\\t\", header=None, names=[\"label\", \"sequence\"])\n",
    "    data[\"encoded\"] = data[\"sequence\"].apply(encode_sequence)\n",
    "    return data\n",
    "\n",
    "def train_hmm_per_label(train_data, n_states=4):\n",
    "    label_hmms = {}\n",
    "    for label in sorted(train_data['label'].unique()):\n",
    "        label_data = train_data[train_data['label'] == label]\n",
    "        sequences = label_data['encoded'].tolist()\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        X = np.concatenate([np.array(seq) for seq in sequences]).reshape(-1, 1)\n",
    "\n",
    "        model = hmm.CategoricalHMM(n_components=n_states, n_iter=100, tol=1e-5, init_params='ste',algorithm='viterbi', verbose=1)\n",
    "        model.fit(X, lengths)\n",
    "        label_hmms[label] = model\n",
    "    return label_hmms\n",
    "\n",
    "def predict_labels(hmm_models, data):\n",
    "    predictions = []\n",
    "    for seq in data['encoded']:\n",
    "        seq_array = np.array(seq).reshape(-1, 1)\n",
    "        scores = {label: model.score(seq_array) for label, model in hmm_models.items()}\n",
    "        pred_label = max(scores, key=scores.get)\n",
    "        predictions.append(pred_label)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mNqbsUnTx3fH"
   },
   "outputs": [],
   "source": [
    "def evaluate(true_labels, pred_labels, set_name=\"Test\"):\n",
    "    print(f\"\\n--- {set_name} Set Evaluation ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(true_labels, pred_labels))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(true_labels, pred_labels))\n",
    "    print(\"Classification Report:\\n\", classification_report(true_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h33IHHITTGUE"
   },
   "outputs": [],
   "source": [
    "nucleotide_map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jCF7xX2ex3Wi"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = load_data(\"data/pwm_seq_200bp_train_set.txt\")\n",
    "test = load_data(\"data/pwm_seq_200bp_test_set.txt\")\n",
    "valid = load_data(\"data/pwm_seq_200bp_valid_set.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dx7TwbzMx3D6"
   },
   "outputs": [],
   "source": [
    "# Train HMMs\n",
    "hmm_models = train_hmm_per_label(train, n_states=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgTZ6Efb35aT",
    "outputId": "b7276c1c-2002-4cfa-abea-688e188de301"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhmm_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstartprob_, hmm_models[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39memissionprob_ , hmm_models[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtransmat_\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "hmm_models[1].startprob_, hmm_models[1].emissionprob_ , hmm_models[1].transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujwVshZy4Yr_",
    "outputId": "69dcf3b6-506f-455f-ffe2-0089a07cc19f"
   },
   "outputs": [],
   "source": [
    "\n",
    "hmm_models[0].startprob_, hmm_models[0].emissionprob_ , hmm_models[0].transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFZaQOMw4eqY",
    "outputId": "a525fa98-92d9-4901-fe70-d6dba606dc81"
   },
   "outputs": [],
   "source": [
    "hmm_models[2].startprob_, hmm_models[2].emissionprob_ , hmm_models[2].transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AW59qoPj1n0F",
    "outputId": "7b579428-e794-441f-969d-d84f1dd288ea"
   },
   "outputs": [],
   "source": [
    "hmm_models[3].startprob_, hmm_models[3].emissionprob_ , hmm_models[3].transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOlJvWfnx26e"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "test_preds = predict_labels(hmm_models, test)\n",
    "valid_preds = predict_labels(hmm_models, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ku1eRTF_x2U4",
    "outputId": "15661e59-3d27-44fc-b685-c304f8189c0e"
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate(test['label'], test_preds, \"Test\")\n",
    "evaluate(valid['label'], valid_preds, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UcHC5csZrdo",
    "outputId": "8836c3df-3caf-4c41-93d9-5c11910f3e6f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load sequences and labels\n",
    "def load_data(filepath):\n",
    "    sequences, labels = [], []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            label, seq = line.strip().split('\\t')\n",
    "            sequences.append(seq)\n",
    "            labels.append(int(label))\n",
    "    return sequences, labels\n",
    "\n",
    "def one_hot_encode(seq, seq_len=200):\n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    one_hot = np.zeros((seq_len, 4))\n",
    "    for i, base in enumerate(seq):\n",
    "        if base in mapping:\n",
    "            one_hot[i, mapping[base]] = 1\n",
    "    return one_hot\n",
    "\n",
    "train_sequences, train_labels = load_data(\"/content/data/pwm_seq_200bp_train_set.txt\")\n",
    "test_sequences, test_labels = load_data(\"/content/data/pwm_seq_200bp_test_set.txt\")\n",
    "\n",
    "X_train = np.array([one_hot_encode(seq) for seq in train_sequences])\n",
    "X_test = np.array([one_hot_encode(seq) for seq in test_sequences])\n",
    "y_train = to_categorical(train_labels, num_classes=4)\n",
    "y_test = to_categorical(test_labels, num_classes=4)\n",
    "\n",
    "# CNN Model\n",
    "model = Sequential([\n",
    "    Conv1D(64, 10, activation='relu', input_shape=(200, 4)),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(128, 10, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.1)\n",
    "\n",
    "# Evaluate\n",
    "preds = model.predict(X_test)\n",
    "y_pred_cnn = np.argmax(preds, axis=1)\n",
    "y_true_cnn = np.argmax(y_test, axis=1)\n",
    "print(\"\\nCNN Classification Report:\\n\")\n",
    "print(classification_report(y_true_cnn, y_pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "ZmbofQ1Ykr2W",
    "outputId": "e31353cc-625f-46b5-ba24-db14ea230a8a"
   },
   "outputs": [],
   "source": [
    "#comparing model performance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# HMM Accuracies (based on test and valid dataframes)\n",
    "hmm_test_accuracy = accuracy_score(test['label'], test_preds)\n",
    "hmm_valid_accuracy = accuracy_score(valid['label'], valid_preds)\n",
    "\n",
    "# CNN Accuracies (from earlier code)\n",
    "cnn_test_accuracy = accuracy_score(y_true_cnn, y_pred_cnn)\n",
    "\n",
    "# Plot\n",
    "labels = ['Test']\n",
    "x = range(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar([i - width/2 for i in x], [cnn_test_accuracy], width=width, label='CNN', color='green')\n",
    "plt.bar([i + width/2 for i in x], [hmm_test_accuracy], width=width, label='HMM', color='red')\n",
    "\n",
    "plt.xticks(x, labels)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('CNN vs HMM Accuracy: Test Set')\n",
    "plt.legend()\n",
    "\n",
    "# Annotate\n",
    "for i, (c_acc, h_acc) in enumerate(zip([cnn_test_accuracy], [hmm_test_accuracy])):\n",
    "    plt.text(i - width/2, c_acc + 0.02, f'{c_acc:.2f}', ha='center')\n",
    "    plt.text(i + width/2, h_acc + 0.02, f'{h_acc:.2f}', ha='center')\n",
    "\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoFb2nysYlQ4",
    "outputId": "b61ccfae-eadc-4b44-82e3-6cc86ea1fa5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)\n",
    "cm_cnn_df = pd.DataFrame(cm_cnn, index=[f\"True {i}\" for i in range(4)],\n",
    "                         columns=[f\"Pred {i}\" for i in range(4)])\n",
    "print(\" CNN Confusion Matrix:\")\n",
    "print(cm_cnn_df)\n",
    "\n",
    "# HMM Confusion Matrix\n",
    "cm_hmm = confusion_matrix(test['label'], test_preds)\n",
    "cm_hmm_df = pd.DataFrame(cm_hmm, index=[f\"True {i}\" for i in range(4)],\n",
    "                         columns=[f\"Pred {i}\" for i in range(4)])\n",
    "print(\"\\n HMM Confusion Matrix:\")\n",
    "print(cm_hmm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvXtF16FwkXv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdZWmcY_bGji"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
